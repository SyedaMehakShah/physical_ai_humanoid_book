---
sidebar_position: 2
---

# Glossary of Terms: Physical AI & Humanoid Robotics

## Learning Objectives
- Understand key terminology in physical AI and humanoid robotics
- Learn the precise definitions of technical terms used in the field
- Become familiar with acronyms and abbreviations common in robotics
- Master the vocabulary needed for effective communication in the field

## A

**Actuator**: A component of a robot that converts energy into mechanical motion. Common types include electric motors, hydraulic cylinders, and pneumatic cylinders.

**Admittance Control**: A control strategy where the robot's motion is governed by applied forces, making it compliant and safe for human interaction. The relationship is: Motion = Admittance × Force.

**Affordance**: A property of an object that suggests how it can be used. In robotics, this refers to how objects in the environment suggest possible interactions to the robot.

**AI Agent**: An autonomous entity that perceives its environment and takes actions to achieve goals. In robotics, AI agents control robot behavior.

**Articulated Robot**: A robot with rotary joints that allow movement in multiple directions, similar to human limbs.

**Autonomous System**: A system that can operate independently without continuous human intervention.

## B

**Balance Control**: Algorithms and mechanisms that maintain a robot's stability, particularly important for bipedal humanoid robots.

**Bipedal Locomotion**: Walking on two legs, the primary mode of movement for humanoid robots designed to navigate human environments.

**Body Schema**: The robot's internal representation of its own body structure, used for movement planning and self-awareness.

**Brain-Computer Interface (BCI)**: A system that enables direct communication between the brain and external devices, potentially allowing thought-controlled robot operation.

**Buffer**: A temporary storage area used to hold data while it's being transferred between different parts of a system.

## C

**Cartesian Coordinates**: A coordinate system that specifies each point uniquely in a plane by a pair of numerical coordinates, typically used for specifying robot end-effector positions.

**Center of Mass (COM)**: The point in a robot where the total mass is concentrated; critical for balance and stability calculations.

**Center of Pressure (COP)**: The point where the total sum of the pressure field acts on a surface; important for bipedal stability.

**Collision Detection**: Algorithms that determine when two objects come into contact, essential for robot safety.

**Command Interface**: The system through which humans can send instructions to a robot.

**Compliance Control**: Control strategy that allows controlled flexibility in robot motion, making interactions safer.

**Computer Vision**: The field of study that enables computers to interpret and understand visual information from the world.

**Constitution**: In the context of Spec-Kit Plus, a document that establishes the fundamental principles and rules governing a project's development.

**Control Loop**: A feedback mechanism that continuously adjusts robot behavior based on sensor input.

**Covariance**: A measure of how much two random variables change together, important in sensor fusion and state estimation.

**Cyber-Physical System**: A system with tight integration between computational and physical elements, characteristic of modern robots.

## D

**Dexterous Manipulation**: The ability to skillfully handle and manipulate objects, similar to human hand dexterity.

**Digital Twin**: A virtual replica of a physical robot that mirrors its properties and behaviors in real-time.

**Direct Kinematics**: The computation of the end-effector position and orientation given the joint angles.

**Discrete Event System**: A system where state changes occur instantaneously in response to events, used in robot task planning.

**Distributed Control**: A control architecture where multiple controllers work together, each managing different aspects of robot behavior.

**Domain Randomization**: A technique in simulation where environment parameters are randomly varied to improve sim-to-real transfer.

**Dynamics**: The study of forces and torques and their effect on motion; essential for robot control.

## E

**Embodied AI**: Artificial intelligence that is integrated with a physical body, enabling interaction with the real world.

**Embodiment**: The concept that intelligence emerges from the interaction between an agent and its physical environment.

**End Effector**: The device at the end of a robot arm that interacts with the environment, such as a gripper or tool.

**Episodic Memory**: A component of robot memory that stores sequences of experiences, important for learning and adaptation.

**Ethical AI**: Artificial intelligence designed and operated according to moral principles and values.

**Euclidean Distance**: The straight-line distance between two points in Euclidean space, commonly used in robot navigation.

**Event-Driven Architecture**: A software architecture pattern where the flow of the program is determined by events, useful for reactive robot behaviors.

## F

**Force Control**: A control strategy that regulates the forces applied by a robot, important for safe human-robot interaction.

**Forward Kinematics**: The computation of the end-effector position and orientation given the joint angles.

**Fuzzy Logic**: A mathematical approach to handle uncertainty and imprecision, useful in robot decision-making.

## G

**Gazebo**: A 3D simulation environment that provides accurate physics simulation for robotics applications.

**Geometric Algebra**: A mathematical framework for representing geometric transformations, useful in robotics.

**Gripper**: A device attached to a robot arm that can grasp and hold objects.

**Grounded Language Learning**: The process of learning language in the context of physical interaction with the world.

**Gyroscopic Effect**: The tendency of a rotating object to maintain its axis of rotation, relevant to robot stability.

## H

**Haptic Feedback**: The use of touch and motion feedback to communicate information to a user.

**Heuristic**: A practical approach to problem-solving that is not guaranteed to be optimal but is sufficient for a given set of goals.

**Human-Robot Collaboration**: A mode of operation where humans and robots work together on tasks.

**Human-Robot Interaction (HRI)**: The study of interactions between humans and robots.

**Humanoid Robot**: A robot designed to resemble the human body structure, typically with a head, torso, two arms, and two legs.

**Hyperparameter**: A parameter whose value is set before the learning process begins, determining the structure of the model.

## I

**Impedance Control**: A control strategy that regulates the relationship between force and motion, making robots compliant for safe interaction.

**Inverse Dynamics**: The computation of forces and torques required to achieve a desired motion.

**Inverse Kinematics**: The computation of joint angles required to achieve a desired end-effector position and orientation.

**IoT (Internet of Things)**: A network of interconnected devices that can collect and exchange data, relevant to connected robotics.

**Isaac Sim**: NVIDIA's simulation environment for robotics, providing photorealistic rendering and accurate physics.

**Iterative Learning Control (ILC)**: A control technique that improves performance by learning from repeated tasks.

## J

**Jacobian Matrix**: A matrix that describes the relationship between joint velocities and end-effector velocities in robotics.

**Joint Space**: The space defined by the robot's joint angles, as opposed to Cartesian space.

**Jacobian Transpose Method**: A technique for controlling forces in joint space based on desired Cartesian forces.

## K

**Kinematic Chain**: A series of rigid bodies connected by joints, forming the mechanical structure of a robot.

**Kinematics**: The study of motion without considering the forces that cause it.

**Knowledge Graph**: A structured representation of knowledge that shows relationships between entities, useful for robot reasoning.

## L

**Lagrangian Mechanics**: A reformulation of classical mechanics that is useful for deriving equations of motion for robots.

**Laser Range Finder**: A device that measures distance by illuminating a target with a laser and measuring the reflection.

**Leap Motion**: A device that tracks hand and finger movements for gesture-based interaction.

**LiDAR (Light Detection and Ranging)**: A remote sensing method that uses light in the form of a pulsed laser to measure distances.

**Locomotion**: The ability to move from one place to another, a key capability for mobile robots.

**Long Short-Term Memory (LSTM)**: A type of recurrent neural network capable of learning long-term dependencies, useful for robot sequence modeling.

## M

**Machine Learning**: A subset of AI that enables systems to learn and improve from experience without being explicitly programmed.

**Manipulator**: A robot arm designed to manipulate objects in the environment.

**Manifold Learning**: A class of machine learning techniques that assumes data lies on a low-dimensional manifold embedded in a higher-dimensional space.

**Marker-Based Tracking**: A technique that uses visual markers to track the position and orientation of objects.

**Matrix Decomposition**: The factorization of a matrix into a product of matrices, useful in solving robotics problems.

**Mechanism Design**: The study of systems whose participants are self-interested agents, relevant to multi-robot systems.

**Middleware**: Software that provides common services and capabilities to applications beyond what's offered by the operating system.

**Mobile Robot**: A robot that can move around in its environment using wheels, tracks, legs, or other means.

**Monte Carlo Method**: A computational technique that uses random sampling to obtain numerical results, useful in robotics for uncertainty propagation.

**Motion Capture**: The process of recording the movement of objects or people, used for robot imitation learning.

**Multi-Agent System**: A system composed of multiple interacting intelligent agents, applicable to multi-robot coordination.

## N

**Natural Language Processing (NLP)**: The ability of a computer program to understand human language as it is spoken or written.

**Neural Network**: A computing system inspired by biological neural networks that constitute animal brains.

**Non-Holonomic Constraint**: A constraint that cannot be integrated to form a constraint on positions alone, common in wheeled robots.

**Norm**: A function that assigns a strictly positive length or size to each vector in a vector space, used in robotics optimization.

## O

**Occupancy Grid**: A probabilistic spatial representation used in robotics to model the environment.

**Operational Space**: The space in which robot tasks are naturally expressed, typically Cartesian space.

**Optimization**: The process of making a system or design as effective or functional as possible.

**Ordinal Optimization**: A method for ranking and selection in optimization problems with stochastic elements.

**Orthogonal Matrix**: A square matrix whose transpose equals its inverse, important in rotation representations.

**Oscillator**: A dynamical system that exhibits periodic behavior, used in rhythmic robot movements.

## P

**Parallel Computing**: A type of computation in which many calculations are carried out simultaneously, important for real-time robotics.

**Partially Observable Markov Decision Process (POMDP)**: A framework for modeling decision-making in situations where the robot has incomplete information.

**Path Planning**: The computational process of finding a feasible path from a start to a goal position.

**Pattern Recognition**: The automated identification of patterns and regularities in data, essential for robot perception.

**Pendulum Model**: A simplified model of bipedal walking based on inverted pendulum dynamics.

**Perception**: The process of acquiring, interpreting, selecting, and organizing sensory information, crucial for robot autonomy.

**PID Controller**: A control loop feedback mechanism widely used in robotics to maintain desired states.

**Point Cloud**: A collection of data points in space, typically representing the external surface of an object, used in 3D mapping.

**Polynomial Interpolation**: A method for constructing polynomials that pass through a given set of points, used in trajectory generation.

**Probabilistic Robotics**: An approach to robotics that explicitly accounts for uncertainty using probability theory.

**Proportional Control**: A control method where the control variable is proportional to the error signal.

**Proprioception**: The sense of the relative position of one's own parts of the body and strength of effort being employed in movement.

## Q

**Quaternion**: A mathematical construct used to represent rotations in 3D space, avoiding the gimbal lock problem of Euler angles.

**Q-Learning**: A model-free reinforcement learning algorithm that learns a policy telling an agent what action to take under what circumstances.

## R

**Reachability**: The property of a system that indicates whether a particular state can be reached from another state.

**Reactive System**: A system that responds to changes in its environment, fundamental to robot autonomy.

**Reinforcement Learning**: A type of machine learning where an agent learns to make decisions by performing actions and receiving rewards or penalties.

**Representational State**: The internal state that a robot maintains to represent its understanding of the world.

**Robot Operating System (ROS)**: A flexible framework for writing robot software that provides services designed for a heterogeneous computer cluster.

**ROS 2**: The second generation of the Robot Operating System, designed for production robotics applications.

**Rotary Joint**: A joint that allows rotational movement around a single axis.

## S

**Safety-Critical System**: A system whose failure could result in human death or serious injury, environmental damage, or financial loss.

**Sensor Fusion**: The process of combining data from multiple sensors to improve the accuracy and reliability of information.

**Servo Motor**: A rotary actuator that allows for precise control of angular position, velocity, and acceleration.

**SLAM (Simultaneous Localization and Mapping)**: The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it.

**Social Robot**: A robot that interacts with humans in a natural and socially acceptable manner.

**Spec-Driven Development**: A development methodology that emphasizes creating specifications before implementation.

**State Estimation**: The process of estimating the internal state of a system from measurements, crucial for robot autonomy.

**Supervised Learning**: A machine learning paradigm where the model learns from labeled training data.

**Support Polygon**: The convex hull of the ground contact points of a robot, used in balance control.

## T

**Task Planning**: The process of determining a sequence of actions to achieve a goal, important for robot autonomy.

**Teleoperation**: The remote operation of a robot by a human operator.

**TensorFlow**: An open-source machine learning framework that can be used for robot AI development.

**Trajectory Generation**: The process of creating a time-parameterized path that the robot will follow.

**Trust Region**: A constraint in optimization algorithms that limits the size of steps taken in each iteration.

**Turing Test**: A test of a machine's ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human.

## U

**Uncertainty Quantification**: The science of characterizing and reducing uncertainties in computational and real-world applications.

**Unity**: A real-time 3D development platform used for creating high-fidelity simulations and visualizations for robotics.

**Urdf (Unified Robot Description Format)**: An XML format for representing robot models, including kinematic and dynamic properties.

**User Experience (UX)**: The overall experience of a person using a product such as a robot, especially in terms of how easy or pleasing it is to use.

## V

**Variable Impedance Control**: A control strategy that allows the robot's mechanical impedance to be adjusted in real-time for safe interaction.

**Variational Principle**: A mathematical principle that describes the behavior of a system in terms of minimizing a functional, used in deriving robot dynamics.

**Vector Field**: A mathematical object that assigns a vector to each point in space, used in robot navigation.

**Virtual Reality (VR)**: A simulated experience that can be similar to or completely different from the real world, used in robot training and simulation.

**Vision System**: The combination of hardware and software that enables a robot to process visual information from its environment.

## W

**Whole-Body Control**: A control approach that considers the entire robot as a unified system rather than controlling individual components separately.

**Workspace**: The space within which a robot manipulator can operate.

**Wrench**: A mathematical representation combining forces and moments acting on a rigid body, important in robot manipulation.

## X

**XACRO (XML Macros)**: An XML macro language that extends URDF with features like constants, scalars, and mathematical expressions.

## Y

**Yaw**: Rotation around the vertical axis of a robot, one of the three rotational degrees of freedom.

## Z

**Zero-Moment Point (ZMP)**: A criterion for dynamic stability of a walking robot, indicating where the ground reaction force would need to act to have no moment about the contact point.

**ZMP Controller**: A controller that ensures the Zero-Moment Point remains within the support polygon for stable walking.

## Acronyms and Abbreviations

**AI**: Artificial Intelligence
**API**: Application Programming Interface
**BCI**: Brain-Computer Interface
**CAD**: Computer-Aided Design
**CI/CD**: Continuous Integration/Continuous Deployment
**CNN**: Convolutional Neural Network
**CPU**: Central Processing Unit
**CUDA**: Compute Unified Device Architecture (NVIDIA parallel computing platform)
**DNN**: Deep Neural Network
**DOF**: Degrees of Freedom
**GPU**: Graphics Processing Unit
**GUI**: Graphical User Interface
**HRI**: Human-Robot Interaction
**IoT**: Internet of Things
**IP**: Intellectual Property
**JSON**: JavaScript Object Notation
**LiDAR**: Light Detection and Ranging
**LSTM**: Long Short-Term Memory
**ML**: Machine Learning
**NLP**: Natural Language Processing
**OOP**: Object-Oriented Programming
**PC**: Personal Computer
**POMDP**: Partially Observable Markov Decision Process
**PRM**: Probabilistic Roadmap
**PVT**: Position, Velocity, Time
**QoS**: Quality of Service
**R&D**: Research and Development
**RAM**: Random Access Memory
**RDBMS**: Relational Database Management System
**RGB-D**: Red Green Blue - Depth
**ROS**: Robot Operating System
**RTOS**: Real-Time Operating System
**RRT**: Rapidly-exploring Random Tree
**SDK**: Software Development Kit
**SLAM**: Simultaneous Localization and Mapping
**SMACH**: State Machine for Autonomous and Hierarchical Control
**SMD**: Surface Mount Device
**SQL**: Structured Query Language
**TCP/IP**: Transmission Control Protocol/Internet Protocol
**UDP**: User Datagram Protocol
**UI**: User Interface
**URI**: Uniform Resource Identifier
**URL**: Uniform Resource Locator
**URDF**: Unified Robot Description Format
**USB**: Universal Serial Bus
**UX**: User Experience
**VM**: Virtual Machine
**VR**: Virtual Reality
**XML**: Extensible Markup Language
**YAML**: YAML Ain't Markup Language
**ZMP**: Zero-Moment Point

## Common Phrases and Concepts

**Embodied Intelligence**: Intelligence that emerges from the interaction between an agent and its physical environment, as opposed to purely abstract symbolic reasoning.

**Physical AI**: The intersection of artificial intelligence and physical systems, focusing on AI agents that interact with the physical world through robotic bodies.

**Sim-to-Real Transfer**: The process of transferring knowledge learned in simulation to real-world robot systems.

**Spec-Kit Plus**: A methodology and toolkit for specification-driven development in Claude Code.

**Docusaurus**: A modern static website generator for documentation, used to build this book.

**Quarter Overview**: A high-level module that introduces the main concepts and learning objectives for the entire quarter.

**Module**: A major section of the curriculum focusing on a specific aspect of humanoid robotics.

**Spec-Driven Workflow**: The process of developing software following the sequence: `/sp.specify` → `/sp.plan` → `/sp.tasks` → `/sp.implement`.

**Constitution**: The foundational document that establishes principles and rules for a project in the Spec-Kit Plus methodology.

**PHR (Prompt History Record)**: A record of user interactions and system responses for traceability and learning.

**ADR (Architecture Decision Record)**: A document that captures significant architectural decisions made during development.

**ROS 2 Ecosystem**: The collection of tools, packages, and frameworks that make up the Robot Operating System 2 environment.

**Humanoid Nervous System**: A metaphor for ROS 2's role as the communication infrastructure connecting different parts of a humanoid robot system.

**Digital Twin**: A virtual representation of a physical robot that mirrors its properties and behaviors in real-time.

**Embodied Intelligence**: Intelligence that emerges from the interaction between an agent and its physical environment.

**Physical AI**: AI systems that interact with and operate in the physical world through robotic embodiments.

**Sim-to-Real Transfer**: The process of transferring knowledge and behaviors learned in simulation to real-world robotic systems.

**Contact-Safe Control**: Control strategies that ensure safe physical interaction between robots and humans.

**Variable Impedance**: The ability to adjust a robot's mechanical resistance to motion in real-time for safe interaction.

**Multimodal Communication**: Communication using multiple channels such as speech, gesture, and visual displays.

**Proxemics**: The study of how humans use space in communication, important for robot navigation around humans.

**Social Navigation**: Navigation that considers social conventions and human comfort in shared spaces.

**Ethical Decision-Making**: Frameworks for making decisions that align with ethical principles and human values.

**Privacy-Preserving**: Techniques that protect personal information while still enabling useful interactions.

**Fairness-Aware**: Systems designed to avoid discrimination and ensure equitable treatment across different user groups.

**Societal Impact**: The effects of robot deployment on society, communities, and individuals.

**Human Dignity**: The fundamental worth and respect that should be preserved in all human-robot interactions.

**Autonomy Support**: Systems that enhance rather than diminish human decision-making capabilities.

**Transparency**: The quality of being open about capabilities, limitations, and decision-making processes.

**Explainability**: The ability to provide understandable explanations for robot behavior and decisions.

**Accountability**: The quality of being responsible for one's actions and decisions, especially important in autonomous systems.